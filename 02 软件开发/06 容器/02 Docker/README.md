## Docker

### 核心概念

#### 镜像

它是一个只读的文件和文件夹组合。它包含了容器运行时所需要的所有基础文件和配置信息，是容器启动的基础。

**镜像是 `Docker` 容器启动的先决条件**。

创建镜像方式

1. 从镜像仓库拉取。例如 `Docker Hub` 官方镜像仓库
2. 自己基于已有镜像自定义。
3. 编写 `Dockerfile` 构建镜像。

#### 容器

容器是镜像的运行实体。镜像是静态的只读文件，而容器带有运行时需要的可写文件层，并且容器中的进程属于运行状态。即**容器运行着真正的应用进程。容器有初建、运行、停止、暂停和删除五种状态。**

虽然容器的本质是主机上运行的一个进程，但是容器有自己独立的命名空间隔离和资源限制。也就是说，在容器内部，无法看到主机上的进程、环境变量、网络等信息，这是容器与直接运行在主机上进程的本质区别。

#### 仓库

`Docker` 的镜像仓库类似于代码仓库，用来存储和分发 `Docker` 镜像。镜像仓库分为公共镜像仓库和私有镜像仓库。

### 组件

| 组件分类           | 组件名称        | 作用剖析                                                     |
| ------------------ | --------------- | ------------------------------------------------------------ |
| docker相关组件     | docker          | docker的客户端，负责发送docker操作请求。                     |
|                    | dockerd         | docker服务端入口，负责接收客户端请求并返回请求结果。         |
|                    | docker-init     | 当业务主进程没有进程回收能力时，docker-init可以作为容器的1号进程，负责管理容器内进程。 |
|                    | docker-proxy    | 用来做docker的网络实现，通过设置iptables规则使得访问到主机的流量可以被顺利转发到容器中。 |
| containerd相关组件 | containerd      | 负责管理容器的生命周期，通过接收dockerd的请求，执行启动或者销毁容器的操作。 |
|                    | containerd-shim | 将containerd和真正的容器进程解耦，使得containerd-shim作为容器进程的父进程，可以实现重启containerd不影响已经启动的容器进程。 |
|                    | ctr             | containerd的客户端，可以直接向containerd发送容器操作请求，主要用来开发和调试。 |
| 容器运行时组件     | runc            | 通过调用Namespace、cgroups等系统接口，实现容器的创建和销毁。 |

### 网络模型

| Libnetwork常见网络模式     | 作用                                                        | 业务场景                                                     |
| -------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
| null空网络模式             | 不提供任何容器网络                                          | 处理一些保密数据，出于安全考虑，需要一个隔离的网络环境执行一些纯计算任务 |
| bridge桥接模式（**默认**） | 使得容器和容器（主机）之间网络可以互通                      | 容器需要实现网络通信或者提供网络服务                         |
| host主机网络模式           | 让容器内的程序可以使用主机的网络                            | 容器需要控制主机网络或者主机网络提供服务                     |
| container网络模式          | 将两个容器放到同一网络空间中，可以直接通过localhost本地访问 | 一般用于网络接管或代理场景                                   |

### 核心原理

#### 命名空间（Namespace）

`Namespace` 是 `Linux` 内核的一个特性，该特性可以实现在同一主机系统中，对进程ID、主机名、用户ID、文件名、网络和进程间通信等资源的隔离。`Docker`利用 `Linux` 内核的 `Namespace` 特性，实现了每个容器的资源相互隔离，从而保证容器内部只能访问到自己`Namespace` 的资源。

| Namespace 名称                   | 作用                                      | Linux内核版本 |
| :------------------------------- | :---------------------------------------- | :------------ |
| Mount（mnt）                     | 隔离挂载点                                | 2.4.19        |
| Process ID (pid)                 | 隔离进程 ID                               | 2.6.24        |
| Network (net)                    | 隔离网络设备，端口号等                    | 2.6.29        |
| Interprocess Communication (ipc) | 隔离 System V IPC 和 POSIX message queues | 2.6.19        |
| UTS Namespace(uts)               | 隔离主机名和域名                          | 2.6.19        |
| User Namespace (user)            | 隔离用户和用户组                          | 3.8           |
| Control group (cgroup) Namespace | 隔离 Cgroups 根目录                       | 4.6           |
| Time Namespace                   | 隔离系统时间                              | 5.6           |

1. Mount namespace

   挂载命名空间允许不同命名空间的进程看到的本地文件位于宿主机中不同路径下，每个命名空间中的进程所看到的文件目录彼此是隔离的。例如，不同命名空间中的进程，都认为自己独占了一个完整的根文件系统（rootfs），但实际上，不同命名空间中的文件彼此隔离，不会造成相互影响，同时也无法影响宿主机文件系统中的其他路径。

2. PID namespace

   Linux通过进程命名空间管理进程号，对于同一进程（同一个task_struct），在不同的命名空间中，看到的进程号不相同。每个进程命名空间有一套自己的进程号管理方法。进程命名空间是一个父子关系的结构，子空间中的进程对于父空间是可见的。

3. IPC namespace

   IPC Namespace 主要是用来隔离进程间通信的。例如 PID Namespace 和 IPC Namespace 一起使用可以实现同一 IPC Namespace 内的进程彼此可以通信，不同 IPC Namespace 的进程却不能通信。

4. NET namespace

   Net Namespace 是用来隔离网络设备、IP 地址和端口等信息的。Net Namespace 可以让每个进程拥有自己独立的 IP 地址，端口和网卡信息。

5. UTS namespace

   UTS（UNIX Time-sharing System）命名空间允许每个容器拥有独立的主机名和域名，从而可以虚拟出一个有独立主机名和网络空间的环境，就跟网络上一台独立的主机一样。

6. User namespace

   每个容器可以有不同的用户和组id，也就是说，可以在容器内使用特定的内部用户执行程序，而非本地系统上存在的用户。每个容器内部都可以有最高权限的root帐号，但跟宿主主机不在一个命名空间。通过使用隔离的用户命名空间，可以提高安全性，避免容器内的进程获取到额外的权限；同时通过使用不同用户也可以进一步在容器内控制权限。

#### 控制组（CGroups）

cgroups（全称：control groups）是 Linux 内核的一个功能，它可以实现限制进程或者进程组的资源（如 CPU、内存、磁盘 IO 等）。

`cgroups` 功能的实现依赖于三个核心概念：子系统、控制组、层级树。

- 子系统（subsystem）：是一个内核的组件，一个子系统代表一类资源调度控制器。例如内存子系统可以限制内存的使用量，CPU 子系统可以限制 CPU 的使用时间。
- 控制组（cgroup）：表示一组进程和一组带有参数的子系统的关联关系。例如，一个进程使用了 CPU 子系统来限制 CPU 的使用时间，则这个进程和 CPU 子系统的关联关系称为控制组。
- 层级树（hierarchy）：是由一系列的控制组按照树状结构排列组成的。这种排列方式可以使得控制组拥有父子关系，子控制组默认拥有父控制组的属性，也就是子控制组会继承于父控制组。比如，系统中定义了一个控制组 c1，限制了 CPU 可以使用 1 核，然后另外一个控制组 c2 想实现既限制 CPU 使用 1 核，同时限制内存使用 2G，那么 c2 就可以直接继承 c1，无须重复定义 CPU 限制。

#### 联合文件系统

联合文件系统（UnionFS）是一种轻量级的高性能分层文件系统，它支持将文件系统中的修改信息作为一次提交，并层层叠加，同时可以将不同目录挂载到同一个虚拟文件系统下，应用看到的是挂载的最终结果。**联合文件系统是实现Docker镜像的技术基础。**

##### AUFS

AUFS 是联合文件系统，意味着它在主机上使用多层目录存储，**每一个目录在 AUFS 中都叫作分支，而在 Docker 中则称之为层（layer），但最终呈现给用户的则是一个普通单层的文件系统，我们把多层以单一层的方式呈现出来的过程叫作联合挂载。**

##### DeviceMapper

Devicemapper 是 Linux 内核提供的框架，从 Linux 内核 2.6.9 版本开始引入，Devicemapper 与 AUFS 不同，AUFS 是一种文件系统，而**Devicemapper 是一种映射块设备的技术框架。**

##### Overlay2

overlay2 和 AUFS 类似，它将所有目录称之为层（layer），overlay2 的目录是镜像和容器分层的基础，而把这些层统一展现到同一的目录下的过程称为联合挂载（union mount）。overlay2 把目录的下一层叫作`lowerdir`，上一层叫作`upperdir`，联合挂载后的结果叫作`merged`。

| 存储驱动      | 特点                                   | 优点                                                         | 缺点                                                         | 适用场景                           |
| ------------- | -------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------- |
| AUFS          | 联合文件系统未并入内核主线，文件级存储 | 作为docker的第一个存储驱动，已经有很长的历史，比较稳定       | 有多层，在做写时复制操作时，如果文件比较大且存在比较低的层，可能会慢一些。 | 大并发但少IO的场景                 |
| OverlayFS     | 联合文件系统并入内核主线，文件级存储   | 只有两层                                                     | 不管修改的内容大小都会复制整个文件，对大文件进行修改要比小文件要消耗更多时间。 | 大并发但少IO的场景                 |
| Device mapper | 并入内核主线，块级存储                 | 块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件 | 不支持共享存储，表示有多个容器读同一个文件时，需要生产多个副本，在很多容器启停的情况下可能会导致磁盘溢出 | 适合IO密集的场景                   |
| BtrFS         | 并入内核，文件级存储                   | 可以像Device mapper一样直接操作底层设备，支持动态添加设备    | 不支持共享存储，表示有多个容器读同一个文件时，需要生产多个副本 | 不适合在高密度容器的PaaS平台上使用 |
| ZFS           | 把所有设备集中到一个存储池中来管理     | 支持多个容器共享一个缓存块，适合内存大的环境                 | COW使碎片化问题更加严重，文件在硬盘上的物理地址会变得不再连续，顺序读会变得性能比较差。 | 适合PaaS和高密度的场景             |

